{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54967</th>\n",
       "      <td>59.50</td>\n",
       "      <td>69.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.50</td>\n",
       "      <td>12.705125</td>\n",
       "      <td>177121500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54966</th>\n",
       "      <td>58.47</td>\n",
       "      <td>65.00</td>\n",
       "      <td>57.50</td>\n",
       "      <td>64.35</td>\n",
       "      <td>14.470351</td>\n",
       "      <td>49746300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54965</th>\n",
       "      <td>67.24</td>\n",
       "      <td>67.70</td>\n",
       "      <td>59.00</td>\n",
       "      <td>59.73</td>\n",
       "      <td>13.431454</td>\n",
       "      <td>37391600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54964</th>\n",
       "      <td>60.63</td>\n",
       "      <td>64.25</td>\n",
       "      <td>59.82</td>\n",
       "      <td>63.25</td>\n",
       "      <td>14.222994</td>\n",
       "      <td>21773000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54963</th>\n",
       "      <td>62.50</td>\n",
       "      <td>64.48</td>\n",
       "      <td>61.57</td>\n",
       "      <td>63.96</td>\n",
       "      <td>14.382652</td>\n",
       "      <td>10777900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1. open  2. high  3. low  4. close  5. adjusted close    6. volume  \\\n",
       "54967    59.50    69.00   55.00     56.50          12.705125  177121500.0   \n",
       "54966    58.47    65.00   57.50     64.35          14.470351   49746300.0   \n",
       "54965    67.24    67.70   59.00     59.73          13.431454   37391600.0   \n",
       "54964    60.63    64.25   59.82     63.25          14.222994   21773000.0   \n",
       "54963    62.50    64.48   61.57     63.96          14.382652   10777900.0   \n",
       "\n",
       "       7. dividend amount  8. split coefficient  company  \n",
       "54967                 0.0                   1.0       10  \n",
       "54966                 0.0                   1.0       10  \n",
       "54965                 0.0                   1.0       10  \n",
       "54964                 0.0                   1.0       10  \n",
       "54963                 0.0                   1.0       10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_csvs_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Combines all CSV files in a folder into a single pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the concatenated data from all CSV files in the input folder.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension to read all CSV files in the folder into a list of DataFrames.\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Use a list comprehension to get the filenames of all CSV files in the folder.\n",
    "    filenames = [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Add a column to each DataFrame containing the filename.\n",
    "    for df, filename in zip(dfs, filenames):\n",
    "        df['company'] = filename\n",
    "\n",
    "    # Concatenate all of the DataFrames into a single DataFrame.\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "df = combine_csvs_from_folder('market_data/TimeSeries/')\n",
    "\n",
    "# convert the company column to integers\n",
    "df['company'] = df['company'].astype('category')\n",
    "df['company'] = df['company'].cat.codes\n",
    "\n",
    "\n",
    "# Drop the date column for now\n",
    "df = df.drop(['date'], axis=1)\n",
    "\n",
    "# reverse the dataframe so that the oldest data is at the top \n",
    "df = df[::-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54967</th>\n",
       "      <td>0.014484</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54966</th>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>0.025795</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54965</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.014544</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.063250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54964</th>\n",
       "      <td>0.014786</td>\n",
       "      <td>0.015575</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.015539</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54963</th>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.015636</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1. open   2. high    3. low  4. close  5. adjusted close  6. volume  \\\n",
       "54967  0.014484  0.016836  0.013461  0.013728           0.022605   0.299662   \n",
       "54966  0.014208  0.015774  0.014138  0.015834           0.025795   0.084153   \n",
       "54965  0.016554  0.016491  0.014544  0.014595           0.023918   0.063250   \n",
       "54964  0.014786  0.015575  0.014766  0.015539           0.025348   0.036825   \n",
       "54963  0.015286  0.015636  0.015240  0.015730           0.025637   0.018222   \n",
       "\n",
       "       7. dividend amount  8. split coefficient  company  \n",
       "54967                 0.0                   0.0      1.0  \n",
       "54966                 0.0                   0.0      1.0  \n",
       "54965                 0.0                   0.0      1.0  \n",
       "54964                 0.0                   0.0      1.0  \n",
       "54963                 0.0                   0.0      1.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_columns(df):\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "df = normalize_columns(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>company</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54967</th>\n",
       "      <td>0.014484</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54966</th>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>0.025795</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54965</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.014544</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.063250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54964</th>\n",
       "      <td>0.014786</td>\n",
       "      <td>0.015575</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.015539</td>\n",
       "      <td>0.025348</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54963</th>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.015636</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1. open   2. high    3. low  4. close  5. adjusted close  6. volume  \\\n",
       "54967  0.014484  0.016836  0.013461  0.013728           0.022605   0.299662   \n",
       "54966  0.014208  0.015774  0.014138  0.015834           0.025795   0.084153   \n",
       "54965  0.016554  0.016491  0.014544  0.014595           0.023918   0.063250   \n",
       "54964  0.014786  0.015575  0.014766  0.015539           0.025348   0.036825   \n",
       "54963  0.015286  0.015636  0.015240  0.015730           0.025637   0.018222   \n",
       "\n",
       "       7. dividend amount  8. split coefficient  company  up  \n",
       "54967                 0.0                   0.0      1.0   0  \n",
       "54966                 0.0                   0.0      1.0   1  \n",
       "54965                 0.0                   0.0      1.0   0  \n",
       "54964                 0.0                   0.0      1.0   0  \n",
       "54963                 0.0                   0.0      1.0   1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the future this should be done in setup but I just did it here for now\n",
    "\n",
    "def add_up_column(df):\n",
    "    # Create empty 'up' and 'down' columns\n",
    "    df['up'] = 0\n",
    "    \n",
    "    # Loop over the rows (skipping the first row)\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i, '4. close'] > df.loc[i-1, '4. close']:\n",
    "            df.loc[i, 'up'] = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df = add_up_column(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0145, 0.0168, 0.0135, 0.0137, 0.2997, 1.0000])\n",
      "torch.Size([54968, 6])\n",
      "torch.Size([54968, 1])\n"
     ]
    }
   ],
   "source": [
    "# neural networks require tensors, so we need to convert our dataframes to tensors\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    #right now this is just getting columns 1-4 (open, low, high, close)\n",
    "    #without date for now\n",
    "    columns = ['1. open', '2. high', '3. low', '4. close', '6. volume', 'company']\n",
    "    inputs = torch.from_numpy(df.loc[:, columns].values.astype('float32'))\n",
    "    targets = torch.from_numpy(df.loc[:, ['up']].values.astype('float32'))\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "inputs, targets = df_to_tensor(df)\n",
    "print(inputs[0])\n",
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a training and validation dataset\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch uses dataloaders to load data in batches\n",
    "\n",
    "batch_size = 8192\n",
    "train_loader = DataLoader(dataset, batch_size, shuffle = True, num_workers = 0)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# use gpu if avaliable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=1028, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=1028, out_features=512, bias=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): GELU(approximate='none')\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 1028),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1028, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, output_size),\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# input size is 4 because we are using open, low, high, close\n",
    "# output size is 1 because we are predicting up=1 or down=0\n",
    "input_size = 6\n",
    "output_size = 1\n",
    "model = NN(input_size, output_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for training\n",
    "# will need to change these a bunch to find out what works best\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.6927850842475891\n",
      "epoch: 10, loss: 0.6913715600967407\n",
      "epoch: 20, loss: 0.6920862197875977\n",
      "epoch: 30, loss: 0.692565381526947\n",
      "epoch: 40, loss: 0.6921563744544983\n",
      "epoch: 50, loss: 0.6917858123779297\n",
      "epoch: 60, loss: 0.6923133730888367\n",
      "epoch: 70, loss: 0.6928710341453552\n",
      "epoch: 80, loss: 0.6916135549545288\n",
      "epoch: 90, loss: 0.6913719177246094\n",
      "epoch: 100, loss: 0.6921842694282532\n",
      "epoch: 110, loss: 0.6920980215072632\n",
      "epoch: 120, loss: 0.6919634938240051\n",
      "epoch: 130, loss: 0.6918247938156128\n",
      "epoch: 140, loss: 0.6918861269950867\n",
      "epoch: 150, loss: 0.6919330954551697\n",
      "epoch: 160, loss: 0.6924799680709839\n",
      "epoch: 170, loss: 0.6925371885299683\n",
      "epoch: 180, loss: 0.6916387677192688\n",
      "epoch: 190, loss: 0.6922420263290405\n",
      "epoch: 200, loss: 0.6915501356124878\n",
      "epoch: 210, loss: 0.6924567818641663\n",
      "epoch: 220, loss: 0.6917755603790283\n",
      "epoch: 230, loss: 0.6918782591819763\n",
      "epoch: 240, loss: 0.6915870308876038\n",
      "epoch: 250, loss: 0.691612184047699\n",
      "epoch: 260, loss: 0.6931259632110596\n",
      "epoch: 270, loss: 0.6938645839691162\n",
      "epoch: 280, loss: 0.6922757625579834\n",
      "epoch: 290, loss: 0.6923117637634277\n",
      "epoch: 300, loss: 0.6912669539451599\n",
      "epoch: 310, loss: 0.6915120482444763\n",
      "epoch: 320, loss: 0.6918928623199463\n",
      "epoch: 330, loss: 0.6907436847686768\n",
      "epoch: 340, loss: 0.6918942332267761\n",
      "epoch: 350, loss: 0.6926254630088806\n",
      "epoch: 360, loss: 0.6928003430366516\n",
      "epoch: 370, loss: 0.6925878524780273\n",
      "epoch: 380, loss: 0.6917140483856201\n",
      "epoch: 390, loss: 0.6919880509376526\n",
      "epoch: 400, loss: 0.6924728751182556\n",
      "epoch: 410, loss: 0.6917783617973328\n",
      "epoch: 420, loss: 0.6921228766441345\n",
      "epoch: 430, loss: 0.6915736794471741\n",
      "epoch: 440, loss: 0.6921992301940918\n",
      "epoch: 450, loss: 0.6918273568153381\n",
      "epoch: 460, loss: 0.6921347975730896\n",
      "epoch: 470, loss: 0.692428469657898\n",
      "epoch: 480, loss: 0.6921451687812805\n",
      "epoch: 490, loss: 0.6913366317749023\n",
      "epoch: 500, loss: 0.6920981407165527\n",
      "epoch: 510, loss: 0.6916089057922363\n",
      "epoch: 520, loss: 0.6918036937713623\n",
      "epoch: 530, loss: 0.6925813555717468\n",
      "epoch: 540, loss: 0.6918145418167114\n",
      "epoch: 550, loss: 0.6923450827598572\n",
      "epoch: 560, loss: 0.691642165184021\n",
      "epoch: 570, loss: 0.6917206645011902\n",
      "epoch: 580, loss: 0.6917403340339661\n",
      "epoch: 590, loss: 0.6904504299163818\n",
      "epoch: 600, loss: 0.6925397515296936\n",
      "epoch: 610, loss: 0.6926339864730835\n",
      "epoch: 620, loss: 0.6916859745979309\n",
      "epoch: 630, loss: 0.6926013231277466\n",
      "epoch: 640, loss: 0.6923664212226868\n",
      "epoch: 650, loss: 0.6920560002326965\n",
      "epoch: 660, loss: 0.6914097666740417\n",
      "epoch: 670, loss: 0.6934807300567627\n",
      "epoch: 680, loss: 0.6919912695884705\n",
      "epoch: 690, loss: 0.6928353309631348\n",
      "epoch: 700, loss: 0.6919218897819519\n",
      "epoch: 710, loss: 0.6929340362548828\n",
      "epoch: 720, loss: 0.6915814876556396\n",
      "epoch: 730, loss: 0.6919533014297485\n",
      "epoch: 740, loss: 0.6918294429779053\n",
      "epoch: 750, loss: 0.6930845975875854\n",
      "epoch: 760, loss: 0.69091796875\n",
      "epoch: 770, loss: 0.6924527287483215\n",
      "epoch: 780, loss: 0.6929309368133545\n",
      "epoch: 790, loss: 0.6908020973205566\n",
      "epoch: 800, loss: 0.692509114742279\n",
      "epoch: 810, loss: 0.6915347576141357\n",
      "epoch: 820, loss: 0.6919970512390137\n",
      "epoch: 830, loss: 0.6922933459281921\n",
      "epoch: 840, loss: 0.692649781703949\n",
      "epoch: 850, loss: 0.692218542098999\n",
      "epoch: 860, loss: 0.6916351318359375\n",
      "epoch: 870, loss: 0.6911789178848267\n",
      "epoch: 880, loss: 0.6925143003463745\n",
      "epoch: 890, loss: 0.6929563283920288\n",
      "epoch: 900, loss: 0.6918055415153503\n",
      "epoch: 910, loss: 0.6918396949768066\n",
      "epoch: 920, loss: 0.692196786403656\n",
      "epoch: 930, loss: 0.6924631595611572\n",
      "epoch: 940, loss: 0.6926809549331665\n",
      "epoch: 950, loss: 0.6923953890800476\n",
      "epoch: 960, loss: 0.6923791170120239\n",
      "epoch: 970, loss: 0.6919881701469421\n",
      "epoch: 980, loss: 0.6920825242996216\n",
      "epoch: 990, loss: 0.6931995153427124\n",
      "epoch: 999, loss: 0.6920541524887085\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epoch % 10 == 0 or epoch == num_epochs - 1):\n",
    "        print(f'epoch: {epoch}, loss: {loss.item()}')\n",
    "        train_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.6926552913547624, val_acc: 0.5150991449881753\n"
     ]
    }
   ],
   "source": [
    "def validate(model, dataloader, criterion):\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculation for efficiency\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device) # Move data to GPU if available\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.float()) # BCE loss expects float inputs\n",
    "            val_loss += loss.item() * inputs.size(0) # Track total validation loss\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    # Calculate average validation loss and accuracy\n",
    "    val_loss /= len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return val_loss, accuracy\n",
    "\n",
    "val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "print(f'val_loss: {val_loss}, val_acc: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:  0.6920541524887085 val_loss:  0.6926552913547624\n"
     ]
    }
   ],
   "source": [
    "print(\"train_loss: \", train_loss, \"val_loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
