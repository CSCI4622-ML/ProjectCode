{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the future this should be done in setup but I just did it here for now\n",
    "\n",
    "# this is actually backward of what it should be since the df starts at present and goes back in time\n",
    "def add_up_column(df):\n",
    "    # Create empty 'up' and 'down' columns\n",
    "    df['up'] = 0\n",
    "    \n",
    "    # Loop over the rows (skipping the first row)\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i, '4. close'] > df.loc[i-1, '4. close']:\n",
    "            df.loc[i, 'up'] = 1\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('market_data/TimeSeries/AAPL.csv')\n",
    "\n",
    "df = add_up_column(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 4])\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "# neural networks require tensors, so we need to convert our dataframes to tensors\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    #right now this is just getting columns 1-4 (open, low, high, close)\n",
    "    inputs = torch.from_numpy(df.iloc[:, 1:5].values.astype('float32'))\n",
    "    outputs = torch.from_numpy(df.iloc[:, 9:].values.astype('float32'))\n",
    "    return inputs, outputs\n",
    "\n",
    "\n",
    "inputs, outputs = df_to_tensor(df)\n",
    "print(inputs.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a training and validation dataset\n",
    "# just random splitting for now \n",
    "\n",
    "dataset = TensorDataset(inputs, outputs)\n",
    "\n",
    "val_percent = 0.2\n",
    "num_rows = len(df.index)\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch likes to use data loaders to load data in batches\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 0)\n",
    "val_loader = DataLoader(val_ds, batch_size, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baselinePredictor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # input size -> 100 -> output size, is baseline nn architecture\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(100, output_size)\n",
    "        self.sigmoid3 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid3(x)\n",
    "        return x\n",
    "\n",
    "# input size is 4 because we are using open, low, high, close\n",
    "# output size is 2 because we are predicting up or down\n",
    "input_size = 4\n",
    "output_size = 1\n",
    "model = baselinePredictor(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for training\n",
    "# will need to change these a bunch to find out what works best\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0001)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.8341\n",
      "Epoch 21/100, Loss: 0.6660\n",
      "Epoch 41/100, Loss: 0.7009\n",
      "Epoch 61/100, Loss: 0.6752\n",
      "Epoch 81/100, Loss: 0.6714\n",
      "Epoch 100/100, Loss: 0.7185\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epoch % 20 == 0 or epoch == num_epochs - 1):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working yet\n",
    "\n",
    "# def get_accuracy(model, loader):\n",
    "#     num_correct = 0\n",
    "#     num_samples = 0\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in loader:\n",
    "#             outputs = model(x)\n",
    "#             _, predictions = outputs.max(1)\n",
    "#             num_correct += (predictions == y).sum()\n",
    "#             num_samples += predictions.size(0)\n",
    "#         print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "\n",
    "# get_accuracy(model, val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out some sample predictions with the trained model\n",
    "\n",
    "def single_prediction(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        # uncomment to see the raw outputs\n",
    "        # return outputs\n",
    "        return torch.clamp(outputs, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([93.5300, 94.1400, 92.3186, 93.5000])\n",
      "tensor([0.4878])\n",
      "tensor([96.1200, 96.4300, 93.6700, 95.8200])\n",
      "tensor([0.4878])\n",
      "tensor([95.1000, 97.0100, 94.8000, 95.7900])\n",
      "tensor([0.4878])\n",
      "tensor([95.3350, 95.6050, 94.2700, 94.5800])\n",
      "tensor([0.4878])\n",
      "tensor([97.8000, 97.9400, 95.6500, 97.2000])\n",
      "tensor([0.4878])\n",
      "tensor([ 99.2100, 100.6300,  98.1000,  98.1500])\n",
      "tensor([0.4878])\n",
      "tensor([ 99.0900, 101.1700,  98.4500, 101.1600])\n",
      "tensor([0.4878])\n",
      "tensor([ 98.4100, 100.9207,  97.5200,  99.7000])\n",
      "tensor([0.4878])\n",
      "tensor([97.8500, 99.6800, 96.9100, 99.5400])\n",
      "tensor([0.4878])\n",
      "tensor([97.5600, 98.8163, 96.2300, 97.6100])\n",
      "tensor([0.4878])\n",
      "tensor([101.3200, 101.7800,  97.5700,  98.2400])\n",
      "tensor([0.4878])\n",
      "tensor([102.0400, 102.6699,  98.7750, 100.0500])\n",
      "tensor([0.4878])\n",
      "tensor([101.1700, 102.4100,  98.0800, 102.1100])\n",
      "tensor([0.4878])\n",
      "tensor([102.9250, 103.9484, 100.6500, 102.1800])\n",
      "tensor([0.4878])\n",
      "tensor([105.2600, 108.7800, 102.5200, 103.3900])\n",
      "tensor([0.4878])\n",
      "tensor([110.2450, 114.0000, 108.8800, 112.9100])\n",
      "tensor([0.4878])\n",
      "tensor([102.5300, 106.2400, 101.2400, 105.1500])\n",
      "tensor([0.4878])\n",
      "tensor([101.1550, 103.3484, 101.1400, 103.1300])\n",
      "tensor([0.4878])\n",
      "tensor([101.0900, 101.7400,  99.0100, 100.5500])\n",
      "tensor([0.4878])\n",
      "tensor([ 99.5300, 103.4850,  99.5300, 102.2400])\n",
      "tensor([0.4878])\n",
      "tensor([98.2350, 99.4900, 96.9200, 99.2200])\n",
      "tensor([0.4878])\n",
      "tensor([92.5600, 97.2400, 91.5200, 97.1800])\n",
      "tensor([0.4878])\n",
      "tensor([96.9300, 98.0900, 96.0000, 96.3200])\n",
      "tensor([0.4878])\n",
      "tensor([97.5600, 97.7800, 95.8600, 97.5200])\n",
      "tensor([0.4878])\n",
      "tensor([93.8600, 97.3540, 93.2025, 97.2500])\n",
      "tensor([0.4878])\n",
      "tensor([94.7400, 95.4400, 92.8600, 93.6800])\n",
      "tensor([0.4878])\n",
      "tensor([97.2500, 99.3200, 95.3800, 95.4600])\n",
      "tensor([0.4878])\n",
      "tensor([98.6800, 98.8900, 95.7300, 96.0500])\n",
      "tensor([0.4878])\n",
      "tensor([94.1800, 98.3700, 94.1200, 98.1200])\n",
      "tensor([0.4878])\n",
      "tensor([96.9300, 97.1900, 93.5000, 95.2700])\n",
      "tensor([0.4878])\n",
      "tensor([90.9300, 95.2600, 90.9300, 95.0900])\n",
      "tensor([0.4878])\n",
      "tensor([87.5700, 90.1850, 87.2900, 89.8700])\n",
      "tensor([0.4878])\n",
      "tensor([87.4600, 89.4800, 87.0800, 87.3600])\n",
      "tensor([0.4878])\n",
      "tensor([83.0300, 86.4000, 81.4300, 86.0800])\n",
      "tensor([0.4878])\n",
      "tensor([85.3300, 85.4200, 83.0700, 83.1200])\n",
      "tensor([0.4878])\n",
      "tensor([86.5500, 86.9800, 83.3600, 85.1400])\n",
      "tensor([0.4878])\n",
      "tensor([85.4600, 86.9600, 84.2050, 85.8200])\n",
      "tensor([0.4878])\n",
      "tensor([83.1200, 84.0500, 82.4700, 84.0000])\n",
      "tensor([0.4878])\n",
      "tensor([82.8700, 84.5500, 82.5500, 84.1800])\n",
      "tensor([0.4878])\n",
      "tensor([82.8000, 83.4800, 81.6900, 81.8200])\n",
      "tensor([0.4878])\n",
      "tensor([84.9700, 85.3500, 83.0000, 83.0400])\n",
      "tensor([0.4878])\n",
      "tensor([83.2500, 85.7800, 82.9344, 85.2500])\n",
      "tensor([0.4878])\n",
      "tensor([85.5200, 85.6800, 82.2500, 83.7900])\n",
      "tensor([0.4878])\n",
      "tensor([86.1750, 87.2250, 85.2100, 86.7700])\n",
      "tensor([0.4878])\n",
      "tensor([85.3300, 86.6100, 84.3300, 85.1900])\n",
      "tensor([0.4878])\n",
      "tensor([87.5100, 87.6300, 84.5100, 84.9200])\n",
      "tensor([0.4878])\n",
      "tensor([88.2650, 89.3500, 86.7300, 87.8600])\n",
      "tensor([0.4878])\n",
      "tensor([89.8900, 89.9700, 87.4700, 88.4500])\n",
      "tensor([0.4878])\n",
      "tensor([92.5020, 93.4581, 89.8700, 91.5800])\n",
      "tensor([0.4878])\n",
      "tensor([95.2300, 96.2500, 90.5200, 92.4900])\n",
      "tensor([0.4878])\n",
      "tensor([89.2100, 90.5800, 87.8700, 90.5500])\n",
      "tensor([0.4878])\n",
      "tensor([88.9000, 90.3000, 88.6300, 89.0900])\n",
      "tensor([0.4878])\n",
      "tensor([89.2400, 90.8600, 87.8800, 90.3500])\n",
      "tensor([0.4878])\n",
      "tensor([88.3400, 89.8900, 87.4800, 88.4600])\n",
      "tensor([0.4878])\n",
      "tensor([90.5000, 91.0400, 87.9000, 88.2500])\n",
      "tensor([0.4878])\n",
      "tensor([93.0500, 94.0600, 90.8200, 91.0100])\n",
      "tensor([0.4878])\n",
      "tensor([94.4750, 95.3600, 93.7800, 94.1300])\n",
      "tensor([0.4878])\n",
      "tensor([96.9900, 97.2300, 94.9200, 95.5000])\n",
      "tensor([0.4878])\n",
      "tensor([92.4700, 96.5400, 91.5250, 96.5400])\n",
      "tensor([0.4878])\n",
      "tensor([94.0400, 94.4100, 91.4400, 92.4200])\n",
      "tensor([0.4878])\n",
      "tensor([93.9300, 96.4000, 93.4300, 93.9500])\n",
      "tensor([0.4878])\n",
      "tensor([93.7900, 94.4300, 93.0650, 93.4100])\n",
      "tensor([0.4878])\n",
      "tensor([93.2400, 94.5800, 92.8300, 94.1300])\n",
      "tensor([0.4878])\n",
      "tensor([92.6200, 93.3500, 90.8700, 93.2000])\n",
      "tensor([0.4878])\n",
      "tensor([93.9700, 95.0200, 90.5900, 92.4600])\n",
      "tensor([0.4878])\n",
      "tensor([95.9500, 95.9900, 92.4800, 94.1400])\n",
      "tensor([0.4878])\n",
      "tensor([95.3700, 96.9700, 94.0300, 94.8500])\n",
      "tensor([0.4878])\n",
      "tensor([96.8500, 98.4879, 95.5400, 97.1200])\n",
      "tensor([0.4878])\n",
      "tensor([103.2100, 103.7900,  97.3400,  98.9400])\n",
      "tensor([0.4878])\n",
      "tensor([ 98.7700, 100.1199,  97.2900,  98.4900])\n",
      "tensor([0.4878])\n",
      "tensor([ 97.8800, 101.1900,  96.6600, 100.7900])\n",
      "tensor([0.4878])\n",
      "tensor([92.9350, 98.6900, 91.6500, 96.6300])\n",
      "tensor([0.4878])\n",
      "tensor([89.4700, 89.4800, 85.8700, 86.1400])\n",
      "tensor([0.4878])\n",
      "tensor([90.7900, 91.7200, 88.2300, 89.9800])\n",
      "tensor([0.4878])\n",
      "tensor([91.9500, 92.1000, 89.0400, 90.5300])\n",
      "tensor([0.4878])\n",
      "tensor([91.4900, 92.4400, 88.0400, 90.9800])\n",
      "tensor([0.4878])\n",
      "tensor([92.4700, 93.5000, 89.0200, 89.3000])\n",
      "tensor([0.4878])\n",
      "tensor([97.3150, 97.7400, 92.0100, 92.1200])\n",
      "tensor([0.4878])\n",
      "tensor([103.9900, 104.5800,  96.0600,  96.7900])\n",
      "tensor([0.4878])\n",
      "tensor([103.5600, 104.8700, 100.7400, 102.4400])\n",
      "tensor([0.4878])\n",
      "tensor([ 97.9050, 103.9600,  97.6600, 103.4100])\n",
      "tensor([0.4878])\n",
      "tensor([113.9200, 114.1200, 109.7700, 110.9600])\n",
      "tensor([0.4878])\n",
      "tensor([116.0000, 119.3457, 114.7600, 115.6600])\n",
      "tensor([0.4878])\n",
      "tensor([119.6500, 121.3152, 118.9500, 120.6000])\n",
      "tensor([0.4878])\n",
      "tensor([119.9800, 120.3900, 116.5700, 119.8200])\n",
      "tensor([0.4878])\n",
      "tensor([114.7920, 119.5900, 114.5000, 119.3200])\n",
      "tensor([0.4878])\n",
      "tensor([113.8300, 118.2400, 113.5100, 115.2500])\n",
      "tensor([0.4878])\n",
      "tensor([114.7100, 116.5932, 113.2200, 115.0700])\n",
      "tensor([0.4878])\n",
      "tensor([119.0600, 119.5200, 114.7900, 116.3600])\n",
      "tensor([0.4878])\n",
      "tensor([110.1100, 114.1900, 110.0900, 113.7900])\n",
      "tensor([0.4878])\n",
      "tensor([114.1000, 114.9600, 106.6000, 106.9000])\n",
      "tensor([0.4878])\n",
      "tensor([107.8800, 113.4400, 105.3450, 112.5300])\n",
      "tensor([0.4878])\n",
      "tensor([112.4900, 113.8300, 111.4000, 112.9000])\n",
      "tensor([0.4878])\n",
      "tensor([112.7100, 115.4800, 110.3900, 112.2100])\n",
      "tensor([0.4878])\n",
      "tensor([115.1000, 116.2500, 112.4300, 113.6700])\n",
      "tensor([0.4878])\n",
      "tensor([118.0000, 118.1700, 113.8800, 114.5600])\n",
      "tensor([0.4878])\n",
      "tensor([120.7700, 121.5300, 119.5000, 120.3000])\n",
      "tensor([0.4878])\n",
      "tensor([118.5800, 121.7500, 117.6900, 120.9500])\n",
      "tensor([0.4878])\n",
      "tensor([119.8900, 123.0000, 119.7900, 121.0900])\n",
      "tensor([0.4878])\n",
      "tensor([113.5800, 116.9100, 112.4500, 115.8800])\n",
      "tensor([0.4878])\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv('market_data/TimeSeries/AMZN.csv')\n",
    "\n",
    "testInputs, testOutputs = df_to_tensor(testdf)\n",
    "\n",
    "for inputs in testInputs:\n",
    "    print(inputs)\n",
    "    print(single_prediction(model, inputs)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4835])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_prediction(model, torch.tensor([ 80, 1,  1, 1])) \n",
    "#theoretically this should be more different gotta fix some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9f1f59101e07bffb7c2ecfaca1a3c7ffe3cd326ee75e914ab1b038684b38c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
