{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csvs_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Combines all CSV files in a folder into a single pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the concatenated data from all CSV files in the input folder.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension to read all CSV files in the folder into a list of DataFrames.\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Concatenate all of the DataFrames into a single DataFrame.\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "df = combine_csvs_from_folder('market_data/TimeSeries/')\n",
    "\n",
    "# Drop the date column for now\n",
    "df = df.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df):\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "df = normalize_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176046</td>\n",
       "      <td>0.173569</td>\n",
       "      <td>0.175851</td>\n",
       "      <td>0.174652</td>\n",
       "      <td>0.182913</td>\n",
       "      <td>0.179121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.182066</td>\n",
       "      <td>0.179904</td>\n",
       "      <td>0.178948</td>\n",
       "      <td>0.180088</td>\n",
       "      <td>0.188316</td>\n",
       "      <td>0.155993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179602</td>\n",
       "      <td>0.179119</td>\n",
       "      <td>0.178785</td>\n",
       "      <td>0.179098</td>\n",
       "      <td>0.187332</td>\n",
       "      <td>0.164548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182288</td>\n",
       "      <td>0.181835</td>\n",
       "      <td>0.181323</td>\n",
       "      <td>0.178229</td>\n",
       "      <td>0.186468</td>\n",
       "      <td>0.190227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.186631</td>\n",
       "      <td>0.185254</td>\n",
       "      <td>0.186305</td>\n",
       "      <td>0.186453</td>\n",
       "      <td>0.194644</td>\n",
       "      <td>0.191133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1. open   2. high    3. low  4. close  5. adjusted close  6. volume  \\\n",
       "0  0.176046  0.173569  0.175851  0.174652           0.182913   0.179121   \n",
       "1  0.182066  0.179904  0.178948  0.180088           0.188316   0.155993   \n",
       "2  0.179602  0.179119  0.178785  0.179098           0.187332   0.164548   \n",
       "3  0.182288  0.181835  0.181323  0.178229           0.186468   0.190227   \n",
       "4  0.186631  0.185254  0.186305  0.186453           0.194644   0.191133   \n",
       "\n",
       "   7. dividend amount  8. split coefficient  up  \n",
       "0                 0.0                   0.0   0  \n",
       "1                 0.0                   0.0   1  \n",
       "2                 0.0                   0.0   0  \n",
       "3                 0.0                   0.0   0  \n",
       "4                 0.0                   0.0   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the future this should be done in setup but I just did it here for now\n",
    "\n",
    "# this is actually backward of what it should be since the df starts at present and goes back in time\n",
    "def add_up_column(df):\n",
    "    # Create empty 'up' and 'down' columns\n",
    "    df['up'] = 0\n",
    "    \n",
    "    # Loop over the rows (skipping the first row)\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i, '4. close'] > df.loc[i-1, '4. close']:\n",
    "            df.loc[i, 'up'] = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df = add_up_column(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1100, 4])\n",
      "torch.Size([1100, 1])\n"
     ]
    }
   ],
   "source": [
    "# neural networks require tensors, so we need to convert our dataframes to tensors\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    #right now this is just getting columns 1-4 (open, low, high, close)\n",
    "    #without date for now\n",
    "    inputs = torch.from_numpy(df.iloc[:, 0:4].values.astype('float32'))\n",
    "    targets = torch.from_numpy(df.iloc[:, 8:].values.astype('float32'))\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "inputs, targets = df_to_tensor(df)\n",
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a training and validation dataset\n",
    "# just making a training dataset for now\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "\n",
    "# val_percent = 0.2\n",
    "# num_rows = len(df.index)\n",
    "# val_size = int(num_rows * val_percent)\n",
    "# train_size = num_rows - val_size\n",
    "# train_ds, val_ds = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch likes to use data loaders to load data in batches\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(dataset, batch_size, shuffle = True, num_workers = 0)\n",
    "#val_loader = DataLoader(val_ds, batch_size, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if avaliable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baselinePredictor(\n",
       "  (layer_1): Linear(in_features=4, out_features=64, bias=True)\n",
       "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class baselinePredictor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(4, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "# input size is 4 because we are using open, low, high, close\n",
    "# output size is 2 because we are predicting up or down\n",
    "input_size = 4\n",
    "output_size = 1\n",
    "model = baselinePredictor(input_size, output_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for training\n",
    "# will need to change these a bunch to find out what works best\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.7361469864845276\n",
      "epoch: 10, loss: 0.7416725754737854\n",
      "epoch: 20, loss: 0.7417689561843872\n",
      "epoch: 30, loss: 0.6503648161888123\n",
      "epoch: 40, loss: 0.6917323470115662\n",
      "epoch: 50, loss: 0.6901987195014954\n",
      "epoch: 60, loss: 0.6590849161148071\n",
      "epoch: 70, loss: 0.7203540802001953\n",
      "epoch: 80, loss: 0.6869814395904541\n",
      "epoch: 90, loss: 0.6461443305015564\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epoch % 10 == 0):\n",
    "        print(f'epoch: {epoch}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working yet\n",
    "\n",
    "# def get_accuracy(model, loader):\n",
    "#     num_correct = 0\n",
    "#     num_samples = 0\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in loader:\n",
    "#             outputs = model(x)\n",
    "#             _, predictions = outputs.max(1)\n",
    "#             num_correct += (predictions == y).sum()\n",
    "#             num_samples += predictions.size(0)\n",
    "#         print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "\n",
    "# get_accuracy(model, val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out some sample predictions with the trained model\n",
    "\n",
    "def single_prediction(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        # uncomment to see the raw outputs\n",
    "        #return outputs\n",
    "        return torch.clamp(outputs, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0314])\n",
      "tensor([0.0347])\n",
      "tensor([0.0365])\n",
      "tensor([0.0300])\n",
      "tensor([0.0385])\n",
      "tensor([0.0409])\n",
      "tensor([0.0429])\n",
      "tensor([0.0408])\n",
      "tensor([0.0380])\n",
      "tensor([0.0395])\n",
      "tensor([0.0349])\n",
      "tensor([0.0353])\n",
      "tensor([0.0378])\n",
      "tensor([0.0293])\n",
      "tensor([0.0125])\n",
      "tensor([0.])\n",
      "tensor([0.0281])\n",
      "tensor([0.0320])\n",
      "tensor([0.0382])\n",
      "tensor([0.0344])\n",
      "tensor([0.0411])\n",
      "tensor([0.0373])\n",
      "tensor([0.0377])\n",
      "tensor([0.0390])\n",
      "tensor([0.0385])\n",
      "tensor([0.0321])\n",
      "tensor([0.0309])\n",
      "tensor([0.0376])\n",
      "tensor([0.0394])\n",
      "tensor([0.0346])\n",
      "tensor([0.0322])\n",
      "tensor([0.0326])\n",
      "tensor([0.0328])\n",
      "tensor([0.0349])\n",
      "tensor([0.0350])\n",
      "tensor([0.0334])\n",
      "tensor([0.0334])\n",
      "tensor([0.0351])\n",
      "tensor([0.0328])\n",
      "tensor([0.0344])\n",
      "tensor([0.0350])\n",
      "tensor([0.0340])\n",
      "tensor([0.0320])\n",
      "tensor([0.0342])\n",
      "tensor([0.0349])\n",
      "tensor([0.0341])\n",
      "tensor([0.0314])\n",
      "tensor([0.0316])\n",
      "tensor([0.0302])\n",
      "tensor([0.0305])\n",
      "tensor([0.0316])\n",
      "tensor([0.0316])\n",
      "tensor([0.0308])\n",
      "tensor([0.0323])\n",
      "tensor([0.0305])\n",
      "tensor([0.0309])\n",
      "tensor([0.0317])\n",
      "tensor([0.0354])\n",
      "tensor([0.0364])\n",
      "tensor([0.0302])\n",
      "tensor([0.0318])\n",
      "tensor([0.0306])\n",
      "tensor([0.0327])\n",
      "tensor([0.0311])\n",
      "tensor([0.0281])\n",
      "tensor([0.0328])\n",
      "tensor([0.0336])\n",
      "tensor([0.0383])\n",
      "tensor([0.0323])\n",
      "tensor([0.0391])\n",
      "tensor([0.0439])\n",
      "tensor([0.0371])\n",
      "tensor([0.0298])\n",
      "tensor([0.0310])\n",
      "tensor([0.0278])\n",
      "tensor([0.0304])\n",
      "tensor([0.0306])\n",
      "tensor([0.0283])\n",
      "tensor([0.0311])\n",
      "tensor([0.0230])\n",
      "tensor([0.0380])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv('market_data/TimeSeries/AMZN.csv')\n",
    "testdf = testdf.drop(['date'], axis=1)\n",
    "testdf = normalize_columns(testdf)\n",
    "testInputs, testOutputs = df_to_tensor(testdf)\n",
    "\n",
    "for inputs in testInputs:\n",
    "    print(single_prediction(model, inputs)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9f1f59101e07bffb7c2ecfaca1a3c7ffe3cd326ee75e914ab1b038684b38c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
