{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>up</th>\n",
       "      <th>down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>147.11</td>\n",
       "      <td>147.19</td>\n",
       "      <td>145.7202</td>\n",
       "      <td>146.71</td>\n",
       "      <td>146.71</td>\n",
       "      <td>55469606.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>150.09</td>\n",
       "      <td>150.34</td>\n",
       "      <td>147.2400</td>\n",
       "      <td>149.40</td>\n",
       "      <td>149.40</td>\n",
       "      <td>48394249.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>148.87</td>\n",
       "      <td>149.95</td>\n",
       "      <td>147.1600</td>\n",
       "      <td>148.91</td>\n",
       "      <td>148.91</td>\n",
       "      <td>51011305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>150.20</td>\n",
       "      <td>151.30</td>\n",
       "      <td>148.4050</td>\n",
       "      <td>148.48</td>\n",
       "      <td>148.48</td>\n",
       "      <td>58867230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>152.35</td>\n",
       "      <td>153.00</td>\n",
       "      <td>150.8500</td>\n",
       "      <td>152.55</td>\n",
       "      <td>152.55</td>\n",
       "      <td>59144118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  1. open  2. high    3. low  4. close  5. adjusted close  \\\n",
       "0  2023-02-24   147.11   147.19  145.7202    146.71             146.71   \n",
       "1  2023-02-23   150.09   150.34  147.2400    149.40             149.40   \n",
       "2  2023-02-22   148.87   149.95  147.1600    148.91             148.91   \n",
       "3  2023-02-21   150.20   151.30  148.4050    148.48             148.48   \n",
       "4  2023-02-17   152.35   153.00  150.8500    152.55             152.55   \n",
       "\n",
       "    6. volume  7. dividend amount  8. split coefficient  up  down  \n",
       "0  55469606.0                 0.0                   1.0   0     0  \n",
       "1  48394249.0                 0.0                   1.0   1     0  \n",
       "2  51011305.0                 0.0                   1.0   0     1  \n",
       "3  58867230.0                 0.0                   1.0   0     1  \n",
       "4  59144118.0                 0.0                   1.0   1     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_up_down_columns(df):\n",
    "    # Create empty 'up' and 'down' columns\n",
    "    df['up'] = 0\n",
    "    df['down'] = 0\n",
    "    \n",
    "    # Loop over the rows (skipping the first row)\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i, '4. close'] > df.loc[i-1, '4. close']:\n",
    "            df.loc[i, 'up'] = 1\n",
    "        else:\n",
    "            df.loc[i, 'down'] = 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('market_data/TimeSeries/AAPL.csv')\n",
    "\n",
    "df = add_up_down_columns(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 4])\n",
      "torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "def df_to_tensor(df):\n",
    "    #right now this is just getting columns 1-4 (open, low, high, close)\n",
    "    inputs = torch.from_numpy(df.iloc[:, 1:5].values.astype('float32'))\n",
    "    outputs = torch.from_numpy(df.iloc[:, 9:11].values.astype('float32'))\n",
    "    return inputs, outputs\n",
    "\n",
    "inputs, outputs = df_to_tensor(df)\n",
    "print(inputs.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, outputs)\n",
    "\n",
    "val_percent = 0.2\n",
    "num_rows = len(df.index)\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 0)\n",
    "val_loader = DataLoader(val_ds, batch_size, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baselinePredictor(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_size = 4\n",
    "output_size = 2\n",
    "model = baselinePredictor(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 712.7229\n",
      "Epoch 2/100, Loss: 703.3522\n",
      "Epoch 3/100, Loss: 697.4349\n",
      "Epoch 4/100, Loss: 700.0151\n",
      "Epoch 5/100, Loss: 694.1405\n",
      "Epoch 6/100, Loss: 693.3485\n",
      "Epoch 7/100, Loss: 685.8510\n",
      "Epoch 8/100, Loss: 690.1052\n",
      "Epoch 9/100, Loss: 679.3253\n",
      "Epoch 10/100, Loss: 671.9378\n",
      "Epoch 11/100, Loss: 671.2245\n",
      "Epoch 12/100, Loss: 668.8616\n",
      "Epoch 13/100, Loss: 656.6287\n",
      "Epoch 14/100, Loss: 657.6114\n",
      "Epoch 15/100, Loss: 652.0363\n",
      "Epoch 16/100, Loss: 651.3932\n",
      "Epoch 17/100, Loss: 652.3797\n",
      "Epoch 18/100, Loss: 640.3760\n",
      "Epoch 19/100, Loss: 639.7733\n",
      "Epoch 20/100, Loss: 631.1075\n",
      "Epoch 21/100, Loss: 633.7534\n",
      "Epoch 22/100, Loss: 625.1565\n",
      "Epoch 23/100, Loss: 626.2050\n",
      "Epoch 24/100, Loss: 620.8696\n",
      "Epoch 25/100, Loss: 617.1561\n",
      "Epoch 26/100, Loss: 611.8804\n",
      "Epoch 27/100, Loss: 608.2168\n",
      "Epoch 28/100, Loss: 610.8741\n",
      "Epoch 29/100, Loss: 607.2321\n",
      "Epoch 30/100, Loss: 600.4810\n",
      "Epoch 31/100, Loss: 600.0148\n",
      "Epoch 32/100, Loss: 588.6575\n",
      "Epoch 33/100, Loss: 585.1290\n",
      "Epoch 34/100, Loss: 584.7149\n",
      "Epoch 35/100, Loss: 575.0494\n",
      "Epoch 36/100, Loss: 577.7445\n",
      "Epoch 37/100, Loss: 575.8218\n",
      "Epoch 38/100, Loss: 569.3250\n",
      "Epoch 39/100, Loss: 570.4871\n",
      "Epoch 40/100, Loss: 561.0060\n",
      "Epoch 41/100, Loss: 557.6429\n",
      "Epoch 42/100, Loss: 554.3001\n",
      "Epoch 43/100, Loss: 553.9885\n",
      "Epoch 44/100, Loss: 552.1761\n",
      "Epoch 45/100, Loss: 548.8773\n",
      "Epoch 46/100, Loss: 539.6301\n",
      "Epoch 47/100, Loss: 539.3666\n",
      "Epoch 48/100, Loss: 539.1033\n",
      "Epoch 49/100, Loss: 537.3615\n",
      "Epoch 50/100, Loss: 532.6805\n",
      "Epoch 51/100, Loss: 528.0286\n",
      "Epoch 52/100, Loss: 526.3360\n",
      "Epoch 53/100, Loss: 520.2696\n",
      "Epoch 54/100, Loss: 518.6110\n",
      "Epoch 55/100, Loss: 511.1524\n",
      "Epoch 56/100, Loss: 505.1886\n",
      "Epoch 57/100, Loss: 509.3674\n",
      "Epoch 58/100, Loss: 503.4423\n",
      "Epoch 59/100, Loss: 509.0346\n",
      "Epoch 60/100, Loss: 501.7122\n",
      "Epoch 61/100, Loss: 498.7153\n",
      "Epoch 62/100, Loss: 494.3140\n",
      "Epoch 63/100, Loss: 488.5219\n",
      "Epoch 64/100, Loss: 488.4205\n",
      "Epoch 65/100, Loss: 485.4995\n",
      "Epoch 66/100, Loss: 481.1908\n",
      "Epoch 67/100, Loss: 478.3095\n",
      "Epoch 68/100, Loss: 475.4455\n",
      "Epoch 69/100, Loss: 469.8134\n",
      "Epoch 70/100, Loss: 472.5472\n",
      "Epoch 71/100, Loss: 466.9560\n",
      "Epoch 72/100, Loss: 464.1600\n",
      "Epoch 73/100, Loss: 462.7569\n",
      "Epoch 74/100, Loss: 458.6174\n",
      "Epoch 75/100, Loss: 454.5035\n",
      "Epoch 76/100, Loss: 454.5061\n",
      "Epoch 77/100, Loss: 454.5074\n",
      "Epoch 78/100, Loss: 447.7293\n",
      "Epoch 79/100, Loss: 447.7516\n",
      "Epoch 80/100, Loss: 441.0348\n",
      "Epoch 81/100, Loss: 445.1080\n",
      "Epoch 82/100, Loss: 438.4379\n",
      "Epoch 83/100, Loss: 434.4805\n",
      "Epoch 84/100, Loss: 430.5475\n",
      "Epoch 85/100, Loss: 429.2936\n",
      "Epoch 86/100, Loss: 428.0466\n",
      "Epoch 87/100, Loss: 424.1674\n",
      "Epoch 88/100, Loss: 421.6277\n",
      "Epoch 89/100, Loss: 417.7914\n",
      "Epoch 90/100, Loss: 419.2096\n",
      "Epoch 91/100, Loss: 415.4023\n",
      "Epoch 92/100, Loss: 409.0186\n",
      "Epoch 93/100, Loss: 413.0430\n",
      "Epoch 94/100, Loss: 409.2874\n",
      "Epoch 95/100, Loss: 405.5549\n",
      "Epoch 96/100, Loss: 404.4143\n",
      "Epoch 97/100, Loss: 398.1576\n",
      "Epoch 98/100, Loss: 398.3237\n",
      "Epoch 99/100, Loss: 392.1233\n",
      "Epoch 100/100, Loss: 389.7690\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not very confident this is doing what I want it to do\n",
    "\n",
    "\n",
    "# def get_num_correct(preds, labels):\n",
    "#     return preds.argmax(dim=1).eq(labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "# total_loss = 0\n",
    "# total_correct = 0\n",
    "\n",
    "# for data in val_loader:\n",
    "#     inputs, labels = data\n",
    "#     outputs = model(inputs)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     total_loss += loss.item()\n",
    "#     total_correct += get_num_correct(outputs, labels)\n",
    "\n",
    "# print(f'Loss: {total_loss/len(val_loader):.4f}, Accuracy: {total_correct/len(val_ds):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_prediction(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        return torch.clamp(outputs, 0, 1)\n",
    "\n",
    "test_input = torch.tensor([[93.53, 94.14, 92.31, 93.5]])\n",
    "single_prediction(model, test_input)\n",
    "# returns [[0, 1]]\n",
    "# our nn thinks it will go down tomorrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9f1f59101e07bffb7c2ecfaca1a3c7ffe3cd326ee75e914ab1b038684b38c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
